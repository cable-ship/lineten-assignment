# Set your preferred Helm release name so related resources follow suit
# Helps keep things tidy when you read cluster resources later on
nameOverride: backend

image:
  # Where the container image actually lives (GCR, ECR, Docker Hub, etc.)
  repository: europe-west2-docker.pkg.dev/org-project/backend-repo/backend

  # Explicit tags beat "latest" when you care about predictable rollouts
  tag: "latest"

  # Choose when Kubernetes should bother pulling the image:
  # - Always: every pod start
  # - IfNotPresent: only if missing locally
  # - Never: rely on whatever is already on the node
  pullPolicy: IfNotPresent

# How many pods you want running in steady state
# Bump this for higher availability or traffic
replicaCount: 2

service:
  # Pick the service exposure model:
  # - ClusterIP: internal only
  # - NodePort: opens a port on every node
  # - LoadBalancer: asks the cloud for an external LB
  type: ClusterIP

  # Clients talk to this port on the Service
  port: 80

  # The containerâ€™s actual listening port
  containerPort: 3000

probes:
  # Readiness gates traffic until the app is actually ready
  readiness:
    httpGet:
      # Endpoint expected to return a 200 when healthy
      path: backend
      port: 3000
    # Give the app a few seconds to boot before probing
    initialDelaySeconds: 5
    # How often Kubernetes should check
    periodSeconds: 10

  # Liveness keeps the pod alive only while the app behaves
  liveness:
    httpGet:
      # Endpoint that signals the app is still kicking
      path: backend
      port: 3000
    # Wait a bit longer before the first liveness check
    initialDelaySeconds: 10
    # Probe cadence once running
    periodSeconds: 10

# External Secrets hook-up (uncomment if you actually use one)
# secrets:
#   # Which SecretStore/ClusterSecretStore to pull from
#   secretStore: gcp-secret-store
#   # Which secret key holds the data
#   key: backend-key_es
#   # Map remote secret properties into Kubernetes secrets
#   data:
#     - name: secret-name
#       property: password

# App-level config that is fine to keep in Git
# configs:
#   # Example of something your app might expect
#   username: user

# Resource budget for each pod (requests = guaranteed, limits = cap)
resources:
  requests:
    # 100m equals a tenth of a CPU core
    cpu: 100m
    memory: 128Mi

  limits:
    # Hard ceiling for CPU
    cpu: 200m
    memory: 256Mi

# Optional: let the HPA scale up/down based on load
autoscaling:
  # Never go below this many pods
  minReplicas: 2

  # Upper bound to avoid runaway costs
  maxReplicas: 5

  # Desired average CPU usage across the fleet
  targetCPUUtilizationPercentage: 80

  # Ditto for memory
  targetMemoryUtilizationPercentage: 70

# Istio ingress bits for reaching the app from outside the cluster
ingress:
  dns:
    # Desired DNS name for the app
    name: backend-dns

    # Where that DNS record should send traffic (gateway/LB IP)
    target: exposed.dns.org.com

    # Add more hostnames if you need them
    additionalHosts: []

  tls:
    # TLS cert common name or secret identifier
    cert: backend

    # How that cert appears inside Kubernetes
    certName: cert-name

  gateway:
    # Gateway resource this VirtualService attaches to
    name: backend

  virtualservice:
    - match:
        - uri:
            # Route everything with this prefix to the app
            prefix: "/"

      # Friendly name for the route
      name: "ping-routes"

      route:
        - destination:
            # Backend service that actually serves the traffic
            host: backend

            port:
              number: 80
